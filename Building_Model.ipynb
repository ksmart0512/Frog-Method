{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Frog Call Identification Method\n",
    "##Building A Classification Model\n",
    "Function that need to be inluded (from libraries, etc):\n",
    "* Fast Fourier Transform for Spectrogram\n",
    "* 2D peak detector, 1D can work as well\n",
    "* MFCC \n",
    "* KNN (machine learning classifier)\n",
    "\n",
    "\n",
    "\n",
    "Method Also requires\n",
    "* .wav reader\n",
    "* Linear Algebra (Matrix multiplication, inversions, scalar/matrix multiplication/division)\n",
    "* Matrix concatenation\n",
    "* Reading data from .txt files\n",
    "\n",
    "This tutorial has code written for python. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Database\n",
    "The database of frog calls from which we build our classification model consists of 15 species with between 9 and 22 calls per species. Each wave file is labeled as the acronym for the common name and the number of the call. For example the first bull frog call is labeled BF01.wav, the second is BF02.wav, etc. Each call also has an user input .txt file with the same name. These files include information on the season, type of call, and other environmental factors that can separate species from other. \n",
    "\n",
    "##Getting Started\n",
    "For this method a a for loop is used to run through the list of .wav files. Before this loop, however, an empty matrix is constructed that will serve as the feature vector matrix for the entire database of calls. This matrix is what will be used in the last steps to build a KNN classifier. \n",
    "\n",
    "```python\n",
    "total_feature_vect_matrix = np.zeros(18) \n",
    "'''\n",
    "In python one can declare an empty array without specified dimensions. However, we will be concatenating matrices to make up the total_feature_vector_matrix, so creating an 18x1 array full of zeros will allow us to do this, then in the end we can eliminate the first vector. \n",
    "'''\n",
    "\n",
    "\n",
    "for file in os.listdir(\"PathName/calls\"):\n",
    "    if file.endswith(\".wav\"):\n",
    "    \n",
    "    #get and read .wav file\n",
    "        file_name = \"calls/\" + file\n",
    "\n",
    "        (rate,sig) = wav.read(file_name)\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Spectrogram\n",
    "Now that we have read the .wav file we can use the FFT to get the log spectrogram of the sound file.\n",
    "\n",
    "```python \n",
    "        # getting log spec\n",
    "        fbank_feat_not_norm = logfbank(sig,rate)\n",
    "       \n",
    "````\n",
    "We also want to normalize the spectrogram so that quite recordings and loud records will be on equal footing while we find the engergy peaks. \n",
    "\n",
    "```python\n",
    "         max_log = np.amax(fbank_feat_not_norm)\n",
    "         fbank_feat = (1/max_log) * fbank_feat_not_norm \n",
    "         '''Multiplying a matrix by a scaler in python is straight foreward:\n",
    "             scalar * matrix\n",
    "            \n",
    "            fbank_feat is now a 2D matrix representing our spectrogram. \n",
    "            we need the X dimension of this matrix as that represents the time length\n",
    "         '''\n",
    "         logSizeY =len(fbank_feat[:,1])# this is the TIME axis\n",
    "         \n",
    "         \n",
    "```\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Peak Finder\n",
    "Finding a good 2D peak detector in python was difficult, so I wen with a 1D peak detector which will scan the spectrogram maxtrix row by row and return the indices (column numbers) where the peaks occur. This may result in multiply peaks in a single column, however, since we don't want duplicate features we will emlinate repeats.\n",
    "\n",
    "```python\n",
    "            spec_peaks_array = [];\n",
    "       \n",
    "            for n in range (0,26): #The spectrogram has 26 rows\n",
    "\n",
    "                ind = detect_peaks(fbank_feat[:,n], mph = 0.8, mpd = 10) \n",
    "'''\n",
    "Thresholds, mph is the max peak height (since we normalized the abosulte max is 1), mpd is the max peak distance, there must be 10 columns between each peak (so we can ignore plateaus)\n",
    "'''\n",
    "               \n",
    "                      \n",
    "                spec_peaks_array = np.concatenate((ind, spec_peaks_array), axis = 0)\n",
    "                #this is now an array with all the columns with peaks\n",
    "                \n",
    "            spec_peaks = list(set(spec_peaks_array))\n",
    "            #this gets rid of duplictes\n",
    "        \n",
    "```\n",
    "\n",
    "###Ratio\n",
    "For quiet calls, background calls, etc the threshold of mpd = 0.8 might be too high. We don't want to miss a frog call if there is one in the background. So we use this ratio to make sure there are enough peaks for use to find the frogs. We want at least 5 peaks per 100 columns. \n",
    "\n",
    "```python\n",
    "            ratio = len(spec_peaks)/logSizeY\n",
    "            if ratio < 0.05:\n",
    "            # we will rerun the above for loop with mph = 0.53\n",
    "            ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##MFCC\n",
    "\n",
    "Now we find the MFCCs for the wav file. Then collect each MFCC corresponding to the column from spec_peaks. These are the features. \n",
    "\n",
    "```python\n",
    "\n",
    "            mfcc_feat_not_norm = mfcc(sig,rate)\n",
    "            #normalize the MFCC's\n",
    "            max_mfcc = np.amax(mfcc_feat_not_norm)\n",
    "            mfcc_feat = (1/max_mfcc) * mfcc_feat_not_norm\n",
    "            mfcc_size = len(mfcc_feat[:,1])\n",
    "            '''mfcc_size must equal logSizeY for the time slices to be equal. Each function (spectrogram, MFCC) should have a default and changable time unit. \n",
    "            '''\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Getting the feature vector matrx\n",
    "Now we have to get the MFCC's we need, add in the user inputs, and add the label. \n",
    "\n",
    "```python\n",
    "            MFCC_features_UI = np.zeros([len(spec_peaks), 18]);\n",
    "            \n",
    "            for counter in range(0, len(spec_peaks)):\n",
    "            \n",
    "```\n",
    "This is matrix full of zeros and the begining of the foor loop to fill it. To add the labels I used if and if else statements to give a different label to each species. ex:\n",
    "\n",
    "```python\n",
    "\n",
    "                if file[:2] == \"BF\": #file is a string\n",
    "                    label = [1];\n",
    "                elif file[:2] == \"BT\":\n",
    "                    label = [2];\n",
    "``` \n",
    "\n",
    "Getting the MFCC\n",
    "\n",
    "```python\n",
    "\n",
    "                time_slice = spec_peaks[counter]\n",
    "                temp = mfcc_feat[time_slice, :]\n",
    "```\n",
    "\n",
    "To get the user inputs, which we have in txt files, we read the file, read it line by line, separate by spaces, save it as an array:\n",
    "\n",
    "```python\n",
    "\n",
    "                for texts in os.listdir(\"/Users/katrinasmart/Desktop/python_shiz/old_data_UI\"):\n",
    "                if file[:5] == texts[:5]:\n",
    "                    text_name = \"old_data_UI/\" + texts\n",
    "                    with open(text_name, 'r') as t:\n",
    "                        line =  [t.readline().strip() for i in range(1)]\n",
    "                        Uinput = [u for u in line]\n",
    "                        UI1 = [ui for ui in u.split(' ')]\n",
    "                        UI = map(int, UI1[:4])\n",
    "                UI = np.array(UI)\n",
    "```\n",
    "\n",
    "Concatenate it all!\n",
    "\n",
    "```python\n",
    "                MFCC_features_UI[counter] = np.concatenate((label,  UI, temp.transpose()), axis = 0)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PCA \n",
    "Principal Componant Analysis Time!! You can find a function to do it for you, however, it is a pretty straight forward equation. The steps are\n",
    "* Take the transpose of the matrix (x) you want to change the basis of (transpose = xT)\n",
    "* Find xT * x\n",
    "* Get the eigan vectors of the resulting matrix\n",
    "* The new projected matrix (your original matrix with a change of basis) is x * [eigan vectors]\n",
    "\n",
    "Note: python indices begin with 0, but from our previous code the first row is all zeros. We leave the first row off by beginning with row 1. Also when slicing matrices [5:] means \"begin at 5 till the end\", [0:5] means \"begin at 0, stop before 5 (at 4)\"\n",
    "\n",
    "```python\n",
    "x = all_data_MFCC_unshifted_label_UI[1:,5:] #we don't want to change the label or the user inputs!  \n",
    "xT = x.T #transpose\n",
    "xTx = np.dot(xT,x) #how to multiply matrices with python. np = numpy\n",
    "eig_val_cov, eig_vec_cov = np.linalg.eig(xTx) #function to get e_vectors and values\n",
    "\n",
    "\n",
    "projection = np.dot(all_data_MFCC_unshifted_label_UI[1:,5:], eig_vec_cov) #matrix with change of basis\n",
    "\n",
    "\n",
    "np.savetxt('PCA_matrix_UI', eig_vec_cov, fmt = '%2.14f') #SAVE THIS!!!\n",
    "```\n",
    "The PCA matrix MUST be saved. We will use this to change the basis of new calls we have to ID. \n",
    "\n",
    "Now we put the labels and the user inputs back on. Just in case the user inputs are unavailable, we also want to build a model with the only user input as the season (0 = winter, 1 = spring, 2 = summer, 3 = fall). Season is the first user input. \n",
    "\n",
    "```python\n",
    "\n",
    "data_shifted_UI = np.concatenate((all_data_MFCC_unshifted_label_UI[1:,0:5], projection), axis = 1)\n",
    "data_shifted = np.concatenate((all_data_MFCC_unshifted_label_UI[1:,0:2], projection), axis = 1)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model \n",
    "KNN is a very common machine learning method. Finding a library with it should not be difficult.\n",
    "First we have to change the data from an array to a list \n",
    "\n",
    "```python\n",
    "training_data_UI = data_shifted_UI[:,1:] # we don't want labels included in the list\n",
    "T_data_UI = []\n",
    "for i in range(0,len(traing_data_UI[:,1]):\n",
    "    data = training_data_UI[i,:]\n",
    "    data = data.tolist()\n",
    "    T_data_UI.append(data)\n",
    "    \n",
    "#The labels also have to be a list, not array    \n",
    "training_labels_UI = data_label_T_UI[0,:]\n",
    "training_labels_UI = training_labels_UI.tolist()\n",
    "\n",
    "#run and build the KNN model\n",
    "neigh_UI = KNeighborsClassifier(n_neighbors=1) \n",
    "neigh_UI.fit(T_data_UI, training_labels_UI ) \n",
    "\n",
    "```\n",
    "\n",
    "Now the object neigh_UI needs to be saved and can be used for new calls. The same process needs to be done with data_shifted. This is the feature vector matrix minus 3 user inputs. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
